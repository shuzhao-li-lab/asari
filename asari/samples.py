import pickle
import multiprocessing as mp
from .mass_functions import flatten_tuplelist
import gzip
import os

def load_from_disk(path):
    if path.endswith(".pickle"):
        return pickle.load(open(path, 'rb'))
    elif path.endswith(".pickle.gz"):
        return pickle.load(gzip.GzipFile(path, 'rb'))

class SimpleSample:
    '''
    Lightweight class of an experimental sample to facilitate workflow.
    The primary use of this class is managing data stroage and retreival at sample level.

    Depending on database_mode, sample list_mass_tracks are stored in memory, or on disk, or in MongoDB.
    Function to get mass tracks from a mzML file is in workflow.process_project and batch_EIC_from_samples_.
    Peaks and empCpds are determined in constructors.CompositeMap.
    '''
    mass_track_cache = {}
    sample_order = None
    order_map = None

    @classmethod
    def populate_order(cls, directory):
        cls.sample_order = sorted([directory + x for x in os.listdir(directory)])
        cls.order_map = {x: i for i, x in enumerate(cls.sample_order)}

    def __init__(self, registry={}, experiment=None, database_mode='ondisk', mode='pos', is_reference=False):
        '''
        Build a lightweight sample class.

        Parameters
        ----------
        registry : dict
            sample_registry, a dictionary like {'sample_id': ii, 'input_file': file}, 
            generated by workflow.register_samples.
        experiment : ext_Experiment instance
            mostly required pointer to ext_Experiment instance, in order to get parameters.
        database_mode : str, optional, default: 'ondisk
            'ondisk' or 'memory' (run in memory, only small studies).
        mode: str, optional, default: 'pos'
            ionization mode, 'pos' or 'neg'. This should be consistent with experiment and registry if given.

        Note
        ----
        m/z calibration is performed in m/z alignment for "small studies", 
        where mass tracks are assembled to MassGrid via landmark peaks with m/z calibration per sample.
        For larger studies, m/z alignment is done via NN clustering, where m/z accuracy 
        is not checked during MassGrid construction. But it is checked during DB annotation.
        '''

        self.__dict__.update(registry)

        self.experiment = experiment
        self.is_reference = is_reference 
            
        self.rt_landmarks = []  # to populate at CMAP.calibrate_sample_RT

        # These are critical RT calibration functions, index mapping with the reference sample
        self.rt_cal_dict = None
        self.reverse_rt_cal_dict = None
        self.is_rt_aligned = is_reference      # init value False unless is_reference
        
        # placeholder
        self.mz_calibration_function = None
        self._cached_mass_tracks = None

    @property
    def database_mode(self):
        return self.experiment.database_mode

    @property
    def mode(self):
        return self.experiment.mode

    @property
    def rt_numbers(self):
        return self.list_scan_numbers

    @property
    def _mz_landmarks_(self):
        return flatten_tuplelist(self.anchor_mz_pairs)  

    @property
    def rt_calibration_records(self):
        return {
            'sample_id': self.sample_id,
            'name': self.name,
            'rt_landmarks': self.rt_landmarks,
            'reverse_rt_cal_dict': self.reverse_rt_cal_dict,
        }

    @property
    def list_mass_tracks(self):
        if self.sample_data:
            return self.sample_data['list_mass_tracks']
        elif self._cached_mass_tracks is not None:
            return self._cached_mass_tracks
        elif self.data_location in SimpleSample.mass_track_cache:
            mass_tracks = SimpleSample.mass_track_cache[self.data_location]
        else:
            if SimpleSample.sample_order is None:
                SimpleSample.populate_order(self.experiment.output_dir + "/pickle/")
            num_preload = self.experiment.parameters['multicores']
            start = SimpleSample.order_map[self.data_location]
            to_load = set(list(SimpleSample.sample_order[start: min(start + num_preload, len(SimpleSample.sample_order))]))
            with mp.Pool(num_preload) as workers:
                results = workers.map(load_from_disk, to_load)
            SimpleSample.mass_track_cache = dict(zip(to_load, [r['list_mass_tracks'] for r in results]))
            mass_tracks = SimpleSample.mass_track_cache[self.data_location]

        if self.is_reference:
            self._cached_mass_tracks = mass_tracks 
        return mass_tracks          