import pickle
import multiprocessing as mp
from .mass_functions import flatten_tuplelist
import gzip
import os
import pandas as pd
import functools
from intervaltree import IntervalTree
from functools import lru_cache, partial
from collections.abc import Iterable

def save_to_disk(path, data):
    if path.endswith(".pickle"):
        with open(path, 'wb') as fh:
            pickle.dump(data, fh, pickle.HIGHEST_PROTOCOL)
    elif path.endswith(".pickle.gz"):
        with gzip.GzipFile(path, 'wb', compresslevel=1) as fh:
            pickle.dump(data, fh, pickle.HIGHEST_PROTOCOL)
    return path, {}

def load_from_disk(path):
    if path.endswith(".pickle"):
        return pickle.load(open(path, 'rb'))
    elif path.endswith(".pickle.gz"):
        return pickle.load(gzip.GzipFile(path, 'rb'))
    
class CachedProperty:
    def __init__(self, func):
        self.func = func
        self.cache = lru_cache()(self.func)

    def __getitem__(self, key):
        return self.cache(key)

class SimpleSample:
    '''
    Lightweight class of an experimental sample to facilitate workflow.
    The primary use of this class is managing data stroage and retreival at sample level.

    Depending on database_mode, sample list_mass_tracks are stored in memory, or on disk, or in MongoDB.
    Function to get mass tracks from a mzML file is in workflow.process_project and batch_EIC_from_samples_.
    Peaks and empCpds are determined in constructors.CompositeMap.
    '''
    mass_track_cache = {}
    sample_order = None
    order_map = None

    @classmethod
    def populate_order(cls, directory):
        cls.sample_order = sorted([directory + x for x in os.listdir(directory)])
        cls.order_map = {x: i for i, x in enumerate(cls.sample_order)}

    def __init__(self, registry={}, experiment=None, database_mode='ondisk', mode='pos', is_reference=False):
        '''
        Build a lightweight sample class.

        Parameters
        ----------
        registry : dict
            sample_registry, a dictionary like {'sample_id': ii, 'input_file': file}, 
            generated by workflow.register_samples.
        experiment : ext_Experiment instance
            mostly required pointer to ext_Experiment instance, in order to get parameters.
        database_mode : str, optional, default: 'ondisk
            'ondisk' or 'memory' (run in memory, only small studies).
        mode: str, optional, default: 'pos'
            ionization mode, 'pos' or 'neg'. This should be consistent with experiment and registry if given.

        Note
        ----
        m/z calibration is performed in m/z alignment for "small studies", 
        where mass tracks are assembled to MassGrid via landmark peaks with m/z calibration per sample.
        For larger studies, m/z alignment is done via NN clustering, where m/z accuracy 
        is not checked during MassGrid construction. But it is checked during DB annotation.
        '''

        self.__dict__.update(registry)

        self.experiment = experiment
        self.is_reference = is_reference 
        self.is_rt_aligned = is_reference
            
        self.rt_landmarks = []  # to populate at CMAP.calibrate_sample_RT

        # These are critical RT calibration functions, index mapping with the reference sample
        self.rt_cal_dict = None
        self.reverse_rt_cal_dict = None
        
        # placeholder
        self.mz_calibration_function = None
        self._cached_mass_tracks = None
    
    @functools.cached_property
    def mz_tree(self):
        __mz_tree = IntervalTree()
        mz_tol = self.experiment.mz_tolerance_ppm
        for t in self.list_mass_tracks:
            t_mz = t['mz']
            t_mz_err = t_mz / 1e6 * mz_tol * 4
            __mz_tree.addi(t_mz - t_mz_err, t_mz + t_mz_err, t['id_number'])
        return __mz_tree

    @property
    def database_mode(self):
        return self.experiment.database_mode

    @property
    def mode(self):
        return self.experiment.mode

    @property
    def rt_numbers(self):
        return self.list_scan_numbers

    @property
    def _mz_landmarks_(self):
        return flatten_tuplelist(self.anchor_mz_pairs)  

    @property
    def rt_calibration_records(self):
        return {
            'sample_id': self.sample_id,
            'name': self.name,
            'rt_landmarks': self.rt_landmarks,
            'reverse_rt_cal_dict': self.reverse_rt_cal_dict,
        }
    
    @property
    def list_mass_tracks(self):
        if self.sample_data:
            return self.sample_data['list_mass_tracks']
        elif self._cached_mass_tracks is not None:
            return self._cached_mass_tracks
        elif self.data_location in SimpleSample.mass_track_cache:
            mass_tracks = SimpleSample.mass_track_cache[self.data_location]
        else:
            if SimpleSample.sample_order is None:
                SimpleSample.populate_order(self.experiment.output_dir + "/pickle/")
            num_preload = self.experiment.parameters['multicores']
            start = SimpleSample.order_map[self.data_location]
            to_load = set(list(SimpleSample.sample_order[start: min(start + num_preload, len(SimpleSample.sample_order))]))
            
            with mp.Pool(num_preload) as workers:
                results = workers.map(load_from_disk, to_load)
            SimpleSample.mass_track_cache = dict(zip(to_load, [r['list_mass_tracks'] for r in results]))
            mass_tracks = SimpleSample.mass_track_cache[self.data_location]
        if self.is_reference:
            self._cached_mass_tracks = mass_tracks 
        return mass_tracks
    
    def tracks_by_mz(self, query_mass):
        track_set = set()
        for x in self.mz_tree.at(float(query_mass) - 1.0072764665789):
            track_set.add(x.data)
        return track_set
    
    def retrieve_tracks_id(self, id):
        if isinstance(id, Iterable):
            return [self.retrieve_tracks_id(x) for x in id]
        return self.retrieve_track_id(id)

    def retrieve_track_id(self, id):
        import matplotlib.pyplot as plt
        for x in self.list_mass_tracks:
            if x['id_number'] == id:
                return x
            
    def find_kovats(self, kovats_csv="/Users/mitchjo/asari/asari/db/kovats.csv"):
        import matplotlib.pyplot as plt
        from .peaks import stats_detect_elution_peaks

        kovats = pd.read_csv(kovats_csv)
        for kovat in kovats.to_dict(orient='records'):
            for t in self.retrieve_tracks_id(self.tracks_by_mz(kovat['mass'])):
                EP = stats_detect_elution_peaks(t,                                           
                                           len(t['intensity']), 
                                           self.experiment.parameters['min_peak_height'],
                                           self.experiment.parameters['min_peak_ratio'],
                                           round(0.5 * self.experiment.parameters['min_timepoints']),
                                           self.experiment.parameters['min_prominence_threshold'],
                                           self.experiment.parameters['wlen'],
                                           self.experiment.parameters['signal_noise_ratio'] * 100,
                                           self.experiment.parameters['gaussian_shape'],
                                           .02,
                                           False,
                                           self.experiment.parameters['min_intensity_threshold'])
                if EP:
                    plt.scatter(range(len(t['intensity'])), t['intensity'], c='k')
                    for p in EP:
                        print(p['apex'], p['height'])
                        plt.scatter(p['apex'], p['height'], c='r')
                    plt.show()
                print(kovat, len(EP))
                for p in EP:
                    print("\t", p)

        exit()




    def find_kovats2(self, kovats_csv="/Users/mitchjo/asari/asari/db/kovats.csv"):
        kovats = pd.read_csv(kovats_csv)
        kovats_hits = []
        for kovat in kovats.to_dict(orient='records'):
            kovat_result = dict(kovat)
            matching_track_ids = self.tracks_by_mz(kovat['mass'])
            matching_tracks = self.retrieve_tracks_id(matching_track_ids)
            likely_track = {'mass_track_id': None,
                            'max_intensity': 0,
                            'apex': None}
            for m_t in matching_tracks:
                apex_tracker = {
                    'intensity': 0,
                    'apex': None
                }
                for i, intensity in enumerate(m_t['intensity']):
                    if intensity > apex_tracker['intensity']:
                        apex_tracker['intensity'] = intensity 
                        apex_tracker['apex'] = i
                if apex_tracker['intensity'] > likely_track['max_intensity']:
                    likely_track['mass_track_id'] = m_t['id_number']
                    likely_track['max_intensity'] = apex_tracker['intensity']
                    likely_track['apex'] = apex_tracker['apex']
            if likely_track['apex']:
                kovat_result.update(likely_track)
                kovats_hits.append(kovat_result)
        return kovats_hits
                





